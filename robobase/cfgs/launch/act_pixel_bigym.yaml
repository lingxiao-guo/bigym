# @package _global_

defaults:
  - ../env: null
  - ../method: act


demos: -1
num_pretrain_steps: 100000
num_train_frames: 0
eval_every_steps: 5000
num_eval_episodes: 50
batch_size: 256
save_snapshot: true
snapshot_every_n: 2500
replay_size_before_train: 500

pixels: true
frame_stack: 1

is_imitation_learning: true

action_repeat: 1
action_sequence: 50
execution_length: 1
temporal_ensemble: true
use_standardization: false  # Demo-based standardization for action space
use_min_max_normalization: true  # Demo-based min-max normalization for action space
min_max_margin: 0
norm_obs: true

update_every_steps: 1

seed: 1
replay:
  nstep: 1

label: False
distill: False
mix: False
policy_class: act
normalized_entropy_threshold: 1
wandb:
  name: act_bigym_${env.task_name}_label_${label}_distill_${distill}_seq_${action_sequence}_threshold_${normalized_entropy_threshold}


hydra:
  run:
    dir: ../exp_local/pixel_act/bigym_${env.task_name}_seed_${seed}_seq_${action_sequence}_label_${label}_distill_${distill}_mix_${mix}_threshold_${normalized_entropy_threshold}

